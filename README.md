
# Project Title

LangChain-based chatbot using Ollamaâ€™s Mistral model

# Description

This project demonstrates how to build a local chatbot application using LangChain, powered by the Mistral model running via Ollama.
It covers core LangChain components including prompt templates and output parsers. 
LangSmith is integrated for real-time tracing and debugging of chains.
## Demo

https://github.com/user-attachments/assets/c5d626d9-9b75-4348-8355-2f32800c99df


## Features

- Modular LangChain Components
  
  Uses essential building blocks: PromptTemplate, LLM, and StrOutputParser for clean and maintainable pipelines.

- Local Mistral Model Deployment with Ollama

  Run powerful open-source LLMs like Mistral completely offline using Ollama.


- Pipeline tracing using LangSmith

  Visualize and debug each step of your LangChain flow using LangSmith's developer-friendly dashboard.

- Streamlit UI for real-time chatbot interaction

  An interactive web interface to chat with your local Mistral-powered chatbot in real time.


## Tech Stack

LangChain

Ollama (Mistral)

Streamlit

LangSmith

Python 3.12
## Screenshots

![Image](https://github.com/user-attachments/assets/a232b4ed-0a47-4492-8e0b-3c4db94d934b)


## Learning Concepts Covered

Recursive vs Character Text Splitting

HTML/JSON-aware splitting

Embeddings: HuggingFace, OpenAI, Ollama

VectorStores: FAISS & Chroma

PromptTemplates, LLMs, OutputParsers

LangSmith Tracing

Streamlit UI Integration